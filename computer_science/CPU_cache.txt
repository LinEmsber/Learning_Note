===============================================================================
                                CPU cache
===============================================================================

A CPU cache is a hardware cache used by the central processing unit (CPU) of a computer to reduce the average
cost (time or energy) to access data from the main memory. The cache is a smaller, faster memory which stores
copies of the data from frequently used main memory locations. Most CPUs have different independent caches,
including instruction and data caches, where the data cache is usually organized as a hierarchy of more cache
levels (L1, L2, etc.).


All modern (fast) CPUs (with few specialized exceptions) have multiple levels of CPU caches. The first CPUs
that used a cache had only one level of cache, not split into L1d (for data) and L1i (for instructions). Almost
all current CPUs with caches have a split L1 cache. They also have L2 caches and, for larger processors, L3
caches as well. The L2 cache is usually not split and is usually shared between cores. The L3 cache, and
higher-level caches, are shared and not split.


Other types of caches exist, such as, the common to all modern CPUs, the translation lookaside buffer (TLB) that
is part of the memory management unit (MMU) that most CPUs have.


When the processor needs to read from or write to a location in main memory, it first checks whether a copy of
that data is in the cache. If so, the processor immediately reads from or writes to the cache, which is much
faster than reading from or writing to main memory.

Most modern desktop and server CPUs have at least three independent caches: an instruction cache to speed up
executable instruction fetch, a data cache to speed up data fetch and store, and a translation lookaside buffer
(TLB) used to speed up virtual-to-physical address translation for both executable instructions and data.


-------------------------------------------------------------------------------

The basic purpose of cache memory is to store program instructions that are frequently re-referenced by software
 during operation. Fast access to these instructions increases the overall speed of the software program.

As the microprocessor processes data, it looks first in the cache memory; if it finds the instructions there (from
a previous reading of data), it does not have to do a more time-consuming reading of data from larger memory or 
other data storage devices.

Most programs use very few resources once they have been opened and operated for a time, mainly because frequently 
re-referenced instructions tend to be cached. This explains why measurements of system performance in computers 
with slower processors but larger caches tend to be faster than measurements of system performance in computers 
with faster processors but more limited cache space.


Cache memory levels explained:

Level 1 (L1) cache is extremely fast but relatively small, and is usually embedded in the processor chip (CPU).

Level 2 (L2) cache is often more capacious than L1; it may be located on the CPU or on a separate chip or 
coprocessor with a high-speed alternative system bus interconnecting the cache to the CPU, so as not to be slowed
by traffic on the main system bus.

Level 3 (L3) cache is typically specialized memory that works to improve the performance of L1 and L2. It can be 
significantly slower than L1 or L2, but is usually double the speed of RAM. In the case of multicore processors, 
each core may have its own dedicated L1 and L2 cache, but share a common L3 cache. When an instruction is referenced 
in the L3 cache, it is typically elevated to a higher tier cache.


References:
Operating Sytem Concepts 9th
https://en.wikipedia.org/wiki/CPU_cache
http://searchstorage.techtarget.com/definition/cache-memory
