===============================================================================
                An Introduction to Lock-Free Programming
===============================================================================

-------------------------------------------------------------------------------
What Is It?
-------------------------------------------------------------------------------

People often describe lock-free programming as programming without mutexes, which are also referred
to as locks. That’s true, but it’s only part of the story. The generally accepted definition, based
on academic literature, is a bit more broad. At its essence, lock-free is a property used to
describe some code, without saying too much about how that code was actually written.



        Are you programming with multiple threads?
        or interrupts, signal handler, etc
                        |
                        |       YES
                        |
                        V
        Do the threads access shared memory?
                        |
                        |       YES
                        |
                        V                                NO
        Can the threads block each other?               --->    It's lock-free programming.
        i.e is there some way to schedule the
        threads which would "lock up" indefinitely?


In this sense, the lock in lock-free does not refer directly to mutexes, but rather to the possibility
of "locking up" the entire application in some way, whether it’s deadlock, livelock.

Shared mutexes are ruled out trivially, because as soon as one thread obtains the mutex, your worst
enemy could simply never schedule that thread again.

Here’s a simple example of an operation which contains no mutexes, but is still not lock-free.
Initially, x = 0. As an exercise for the reader, consider how two threads could be scheduled in a way
such that neither thread exits the loop.

        int x = 0;

        while (x == 0){
            x = 1 - x;
        }

Nobody expects a large application to be entirely lock-free. Typically, we identify a specific set of
lock-free operations out of the whole codebase.


The Art of Multiprocessor Programming:
"In an infinite execution, infinitely often some method call finishes."

In other words, as long as the program is able to keep calling those lock-free operations, the number
of completed calls keeps increasing, no matter what. It is algorithmically impossible for the system
to lock up during those operations.


One important consequence of lock-free programming is that if you suspend a single thread, it will
never prevent other threads from making progress, as a group, through their own lock-free operations.
This hints at the value of lock-free programming when writing interrupt handlers and real-time
systems, where certain tasks must complete within a certain time limit, no matter what state the
rest of the program is in.

-------------------------------------------------------------------------------
Lock-Free Programming Techniques:
-------------------------------------------------------------------------------

It turns out that when you attempt to satisfy the non-blocking condition of lock-free programming, a
whole family of techniques fall out: atomic operations, memory barriers, avoiding the ABA problem, to
name a few.


Atomic Read-Modify-Write Operations

Compare-And-Swap Loops

Sequential Consistency

Memory Ordering

Different Processors Have Different Memory Models




references:
http://preshing.com/20120612/an-introduction-to-lock-free-programming/
